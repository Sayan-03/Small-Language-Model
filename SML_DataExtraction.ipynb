{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e65086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0572e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    def __init__(self,arr):\n",
    "        self.train_root=arr[0]\n",
    "        self.valid_root=arr[1]\n",
    "        self.train_outputFile=arr[2]\n",
    "        self.valid_outputFile=arr[3]\n",
    "        self.vocabularyFile=arr[4]\n",
    "        self.vocab=set()\n",
    "    \n",
    "    def _files_in_directory(self,root):\n",
    "        files=[]\n",
    "        for f_name in os.listdir(root):\n",
    "            if f_name.endswith(\".txt\") and os.path.isfile(os.path.join(root,f_name)):\n",
    "                files.append(f_name)\n",
    "        return files\n",
    "    \n",
    "    def _strip_special_characters(self,word):\n",
    "        pattern=r'[^a-zA-Z0-9\\s]+'\n",
    "        stripped_word=re.sub(pattern,'',word)\n",
    "        return stripped_word\n",
    "    \n",
    "    def _get_words(self,text):\n",
    "        words=text.split()\n",
    "        list_of_words=[]\n",
    "        for word in words:\n",
    "            word=self._strip_special_characters(word)\n",
    "            word=word.strip(\"~`!@#$%^&*()1234567890_-+={[]}\\|'';:\"\"/?.><,\")\n",
    "            if word:\n",
    "                list_of_words.append(word)\n",
    "        return list_of_words\n",
    "    \n",
    "    def get_vocabularyFile(self):\n",
    "        print(f\"Generating the vocabulary file..\\n\")\n",
    "        train_files=self._files_in_directory(self.train_root)\n",
    "        valid_files=self._files_in_directory(self.valid_root)\n",
    "        total_train_files=len(train_files)\n",
    "        total_valid_files=len(valid_files)\n",
    "        \n",
    "        with open(self.train_outputFile,\"w\",encoding=\"utf-8\") as out_file:\n",
    "            for f_name in train_files:\n",
    "                file_path=os.path.join(train_root,f_name)\n",
    "                with open(file_path,\"r\",encoding=\"utf-8\") as in_file:\n",
    "                    text=in_file.read()\n",
    "                    out_file.write(text)\n",
    "                    words=set(self._get_words(text))\n",
    "                    self.vocab.update(words)\n",
    "\n",
    "        with open(self.valid_outputFile,\"w\",encoding=\"utf-8\") as out_file:\n",
    "            for f_name in valid_files:\n",
    "                file_path=os.path.join(valid_root,f_name)\n",
    "                with open(file_path,\"r\",encoding=\"utf-8\") as in_file:\n",
    "                    text=in_file.read()\n",
    "                    out_file.write(text)\n",
    "                    words=set(self._get_words(text))\n",
    "                    self.vocab.update(words)\n",
    "\n",
    "        with open(self.vocabularyFile,\"w\",encoding=\"utf-8\") as v_file:\n",
    "            for word in self.vocab:\n",
    "                v_file.write(word+'\\n')\n",
    "        print(f\"Vocabulary File successfully generated!\\n\")\n",
    "                \n",
    "    def _seek_vocabularyFile(self,slice_num):\n",
    "        with open(self.vocabularyFile,\"r\",encoding=\"utf-8\") as f:\n",
    "            text=f.read()\n",
    "            words=sorted(self._get_words(text))\n",
    "        vocab_size=len(words)\n",
    "        print(f\"Vocabulary File size: {vocab_size}\\n\")\n",
    "        idx=random.randint(slice_num,vocab_size)\n",
    "        print(f\"Your Vocabulary File slice:\\n {words[idx-slice_num:idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba53c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root=\"D:/LLM_Dataset/Books/Train\"\n",
    "valid_root=\"D:/LLM_Dataset/Books/Valid\"\n",
    "train_outputFile=\"D:/LLM_Dataset/output_train.txt\"\n",
    "valid_outputFile=\"D:/LLM_Dataset/output_valid.txt\"\n",
    "vocabularyFile=\"D:/LLM_Dataset/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a8f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=Extractor([train_root,valid_root,train_outputFile,valid_outputFile,vocabularyFile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beebbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the vocabulary file..\n",
      "\n",
      "Vocabulary File successfully generated!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "database.get_vocabularyFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d1eff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary File size: 381401\n",
      "\n",
      "Your Vocabulary File slice:\n",
      " ['spirit', 'spiritalis', 'spirited', 'spiritedly', 'spiritedness', 'spiritful', 'spiritism', 'spiritist', 'spiritless', 'spiritlessness', 'spiritlike', 'spiritmoving', 'spiritous', 'spirits', 'spiritstirring', 'spiritual', 'spiritualis', 'spiritualiser', 'spiritualism', 'spiritualist']\n"
     ]
    }
   ],
   "source": [
    "database._seek_vocabularyFile(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d5c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
